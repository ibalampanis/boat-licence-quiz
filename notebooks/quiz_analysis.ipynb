{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf413d82",
   "metadata": {},
   "source": [
    "# Boat License Quiz Data Analysis\n",
    "\n",
    "This notebook analyzes the questions.json file that contains boat license quiz questions. We'll perform various analyses to understand the structure and content of the quiz, including:\n",
    "\n",
    "1. Loading and exploring the data structure\n",
    "2. Counting the total number of questions\n",
    "3. Analyzing the distribution of correct answers\n",
    "4. Checking the number of options per question\n",
    "5. Finding missing or duplicate question numbers\n",
    "6. Displaying sample questions\n",
    "\n",
    "Let's begin by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0954b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Set plot styles\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Display all dataframe columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2391800",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect the JSON Data\n",
    "\n",
    "First, let's load the questions.json file and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b33aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the questions from the JSON file\n",
    "with open('../questions.json', 'r', encoding='utf-8') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "# Display the first question to understand the structure\n",
    "print(f\"Data type: {type(questions)}\")\n",
    "print(f\"Number of items: {len(questions)}\")\n",
    "print(\"\\nExample of a question entry:\")\n",
    "print(json.dumps(questions[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the questions to a pandas DataFrame for easier analysis\n",
    "# First, extract the options to separate columns\n",
    "questions_processed = []\n",
    "\n",
    "for question in questions:\n",
    "    q_dict = {\n",
    "        'question_number': question['question_number'],\n",
    "        'chapter': question['chapter'],\n",
    "        'question_number_rel': question['question_number_rel'],\n",
    "        'question': question['question'],\n",
    "        'option_a': question['options'].get('a', None),\n",
    "        'option_b': question['options'].get('b', None),\n",
    "        'option_c': question['options'].get('c', None),\n",
    "        'correct_answer': question['correct_answer']\n",
    "    }\n",
    "    questions_processed.append(q_dict)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(questions_processed)\n",
    "\n",
    "# Display DataFrame info and first few rows\n",
    "print(\"DataFrame Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few questions:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a777be",
   "metadata": {},
   "source": [
    "## 2. Count Total Number of Questions\n",
    "\n",
    "Let's calculate the total number of questions in the dataset and check the question numbering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of questions\n",
    "total_questions = len(df)\n",
    "print(f\"Total number of questions in the dataset: {total_questions}\")\n",
    "\n",
    "# Convert question_number to numeric for analysis\n",
    "# Some numbers might be strings\n",
    "df['question_number_numeric'] = pd.to_numeric(df['question_number'], errors='coerce')\n",
    "\n",
    "# Calculate some basic statistics on question numbers\n",
    "min_question = df['question_number_numeric'].min()\n",
    "max_question = df['question_number_numeric'].max()\n",
    "\n",
    "print(f\"Minimum question number: {min_question}\")\n",
    "print(f\"Maximum question number: {max_question}\")\n",
    "print(f\"Expected number of questions (if sequential): {max_question - min_question + 1}\")\n",
    "print(f\"Difference from actual count: {max_question - min_question + 1 - total_questions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bcc17b",
   "metadata": {},
   "source": [
    "## 3. Analyze Distribution of Correct Answers\n",
    "\n",
    "Let's analyze how the correct answers are distributed among options a, b, and c. This can help identify if there's any bias towards a specific answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each correct answer\n",
    "correct_answer_counts = df['correct_answer'].value_counts().sort_index()\n",
    "print(\"Frequency of each correct answer:\")\n",
    "print(correct_answer_counts)\n",
    "\n",
    "# Calculate percentages\n",
    "correct_answer_percentages = (correct_answer_counts / total_questions * 100).round(2)\n",
    "print(\"\\nPercentage distribution of correct answers:\")\n",
    "for answer, percentage in correct_answer_percentages.items():\n",
    "    print(f\"Option {answer}: {percentage}%\")\n",
    "\n",
    "# Create a bar chart to visualize the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(correct_answer_counts.index, correct_answer_counts.values, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height} ({height/total_questions*100:.1f}%)',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of Correct Answers', fontsize=16)\n",
    "plt.xlabel('Answer Option', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Check if there's significant bias using chi-square test\n",
    "from scipy.stats import chisquare\n",
    "expected = np.array([total_questions/3, total_questions/3, total_questions/3])  # Expected uniform distribution\n",
    "observed = correct_answer_counts.values\n",
    "chi2, p_value = chisquare(observed, expected)\n",
    "\n",
    "print(f\"\\nChi-square test for uniform distribution:\")\n",
    "print(f\"Chi2 statistic: {chi2:.2f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"The distribution of correct answers is significantly different from uniform (p < 0.05)\")\n",
    "    # Find which option is overrepresented\n",
    "    most_common = correct_answer_counts.idxmax()\n",
    "    print(f\"Option '{most_common}' appears more frequently as the correct answer.\")\n",
    "else:\n",
    "    print(\"The distribution of correct answers does not significantly differ from uniform (p ≥ 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2f49b",
   "metadata": {},
   "source": [
    "## 4. Count Number of Options per Question\n",
    "\n",
    "Let's verify that all questions have the same number of options and identify any that have missing options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of options per question\n",
    "df['num_options'] = df.apply(lambda row: sum(1 for opt in ['option_a', 'option_b', 'option_c'] if pd.notna(row[opt])), axis=1)\n",
    "\n",
    "# Display distribution of number of options\n",
    "options_counts = df['num_options'].value_counts().sort_index()\n",
    "print(\"Number of questions with each option count:\")\n",
    "print(options_counts)\n",
    "\n",
    "# Create a bar chart to visualize options per question\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(options_counts.index, options_counts.values, color='lightblue')\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height} ({height/total_questions*100:.1f}%)',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.title('Number of Options per Question', fontsize=16)\n",
    "plt.xlabel('Number of Options', fontsize=14)\n",
    "plt.ylabel('Number of Questions', fontsize=14)\n",
    "plt.xticks(range(0, 4), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Find questions with fewer than 3 options\n",
    "if len(df[df['num_options'] < 3]) > 0:\n",
    "    print(\"\\nQuestions with fewer than 3 options:\")\n",
    "    display(df[df['num_options'] < 3][['question_number', 'question', 'num_options']])\n",
    "else:\n",
    "    print(\"\\nAll questions have 3 options.\")\n",
    "\n",
    "# Verify that all questions have options a, b, and c\n",
    "missing_options = []\n",
    "for opt in ['option_a', 'option_b', 'option_c']:\n",
    "    missing = df[df[opt].isna()]\n",
    "    if len(missing) > 0:\n",
    "        missing_options.append((opt, len(missing)))\n",
    "\n",
    "if missing_options:\n",
    "    print(\"\\nMissing options detected:\")\n",
    "    for opt, count in missing_options:\n",
    "        print(f\"{count} questions missing {opt}\")\n",
    "else:\n",
    "    print(\"\\nAll questions have options a, b, and c.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36727bce",
   "metadata": {},
   "source": [
    "## 5. Find Questions with Missing or Duplicate Numbers\n",
    "\n",
    "Let's check for any gaps or duplicates in the question numbering sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate question numbers\n",
    "duplicate_numbers = df[df.duplicated('question_number', keep=False)].sort_values('question_number')\n",
    "if len(duplicate_numbers) > 0:\n",
    "    print(\"Duplicate question numbers found:\")\n",
    "    display(duplicate_numbers[['question_number', 'question']])\n",
    "else:\n",
    "    print(\"No duplicate question numbers found.\")\n",
    "\n",
    "# Check for missing question numbers in the sequence\n",
    "all_numbers = set(df['question_number_numeric'].dropna())\n",
    "expected_range = set(range(int(min_question), int(max_question) + 1))\n",
    "missing_numbers = expected_range - all_numbers\n",
    "\n",
    "if missing_numbers:\n",
    "    print(f\"\\nMissing question numbers: {sorted(missing_numbers)}\")\n",
    "    print(f\"Total missing: {len(missing_numbers)}\")\n",
    "else:\n",
    "    print(\"\\nNo missing question numbers in the sequence.\")\n",
    "\n",
    "# Visualize the question number sequence\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(df['question_number_numeric'], np.ones(len(df)), color='blue', alpha=0.7)\n",
    "plt.title('Question Number Sequence', fontsize=16)\n",
    "plt.xlabel('Question Number', fontsize=14)\n",
    "plt.yticks([])  # Hide y-axis\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Highlight missing numbers if any\n",
    "if missing_numbers:\n",
    "    plt.scatter(list(missing_numbers), np.ones(len(missing_numbers)), color='red', marker='x', s=100, label='Missing')\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Visualize distribution of question numbers\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(df['question_number_numeric'], bins=int(max_question - min_question + 1), \n",
    "         range=(min_question-0.5, max_question+0.5), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Question Numbers', fontsize=16)\n",
    "plt.xlabel('Question Number', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862c7b2",
   "metadata": {},
   "source": [
    "## 6. Display Sample Questions\n",
    "\n",
    "Let's randomly select and display a few sample questions to get a better feel for the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed646542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a formatted question\n",
    "def display_question(q):\n",
    "    print(f\"Question {q['question_number']}: {q['question']}\")\n",
    "    print(f\"A. {q['option_a']}\")\n",
    "    print(f\"B. {q['option_b']}\")\n",
    "    print(f\"C. {q['option_c']}\")\n",
    "    print(f\"Correct Answer: {q['correct_answer'].upper()}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Randomly select 5 questions to display\n",
    "sample_size = min(5, len(df))\n",
    "sample_indices = random.sample(range(len(df)), sample_size)\n",
    "print(f\"Displaying {sample_size} randomly selected questions:\\n\")\n",
    "\n",
    "for idx in sample_indices:\n",
    "    display_question(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ab356",
   "metadata": {},
   "source": [
    "## 7. Additional Analysis: Question and Option Lengths\n",
    "\n",
    "Let's analyze the length of questions and options to understand the complexity of the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lengths of questions and options\n",
    "df['question_length'] = df['question'].str.len()\n",
    "df['option_a_length'] = df['option_a'].str.len()\n",
    "df['option_b_length'] = df['option_b'].str.len()\n",
    "df['option_c_length'] = df['option_c'].str.len()\n",
    "\n",
    "# Get statistics on lengths\n",
    "length_stats = df[['question_length', 'option_a_length', 'option_b_length', 'option_c_length']].describe()\n",
    "print(\"Statistics on lengths of questions and options:\")\n",
    "display(length_stats)\n",
    "\n",
    "# Create histograms for question lengths\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(df['question_length'], bins=15, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Question Length Distribution', fontsize=14)\n",
    "plt.xlabel('Number of Characters', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(df['option_a_length'], bins=15, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "plt.title('Option A Length Distribution', fontsize=14)\n",
    "plt.xlabel('Number of Characters', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(df['option_b_length'], bins=15, color='salmon', edgecolor='black', alpha=0.7)\n",
    "plt.title('Option B Length Distribution', fontsize=14)\n",
    "plt.xlabel('Number of Characters', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(df['option_c_length'], bins=15, color='plum', edgecolor='black', alpha=0.7)\n",
    "plt.title('Option C Length Distribution', fontsize=14)\n",
    "plt.xlabel('Number of Characters', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare average length of correct answer options vs incorrect ones\n",
    "df['correct_option_length'] = df.apply(\n",
    "    lambda row: row[f'option_{row[\"correct_answer\"]}_length'] \n",
    "    if row[\"correct_answer\"] in ['a', 'b', 'c'] else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate average length of incorrect options\n",
    "option_cols = ['option_a_length', 'option_b_length', 'option_c_length']\n",
    "for i, row in df.iterrows():\n",
    "    correct = row['correct_answer']\n",
    "    if correct in ['a', 'b', 'c']:\n",
    "        incorrect_lengths = [row[col] for col in option_cols if col != f'option_{correct}_length']\n",
    "        df.at[i, 'avg_incorrect_length'] = sum(incorrect_lengths) / len(incorrect_lengths)\n",
    "\n",
    "# Compare lengths\n",
    "print(\"\\nAverage length of correct answer options:\", df['correct_option_length'].mean())\n",
    "print(\"Average length of incorrect answer options:\", df['avg_incorrect_length'].mean())\n",
    "\n",
    "# Test if there's a significant difference\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_val = ttest_ind(\n",
    "    df['correct_option_length'].dropna(), \n",
    "    df['avg_incorrect_length'].dropna()\n",
    ")\n",
    "print(f\"\\nt-test results: t={t_stat:.2f}, p={p_val:.4f}\")\n",
    "if p_val < 0.05:\n",
    "    print(\"There is a significant difference in length between correct and incorrect options.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in length between correct and incorrect options.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9eeff8",
   "metadata": {},
   "source": [
    "## 8. Word Frequency Analysis\n",
    "\n",
    "Let's analyze the most common words in questions and options to understand the key topics of the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ede01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and extract words from text\n",
    "def extract_words(text):\n",
    "    import re\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Filter out stopwords and short words\n",
    "    stopwords = ['το', 'τα', 'του', 'της', 'των', 'και', 'με', 'σε', 'από', 'για', 'που', 'τον', 'την', 'στο', 'στη']\n",
    "    words = [word for word in words if word not in stopwords and len(word) > 2]\n",
    "    return words\n",
    "\n",
    "# Combine all questions into a single text\n",
    "all_questions_text = ' '.join(df['question'].tolist())\n",
    "question_words = extract_words(all_questions_text)\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(question_words)\n",
    "most_common_words = word_counts.most_common(20)\n",
    "\n",
    "# Create dataframe for plotting\n",
    "words_df = pd.DataFrame(most_common_words, columns=['word', 'count'])\n",
    "\n",
    "# Create horizontal bar chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "bars = plt.barh(words_df['word'], words_df['count'], color='skyblue')\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width}', ha='left', va='center')\n",
    "\n",
    "plt.title('Top 20 Most Common Words in Questions', fontsize=16)\n",
    "plt.xlabel('Frequency', fontsize=14)\n",
    "plt.ylabel('Word', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()  # To display the most common words at the top\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a word cloud (if wordcloud package is available)\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
    "                          max_words=100, contour_width=3, contour_color='steelblue')\n",
    "    \n",
    "    # Generate from frequency dictionary\n",
    "    wordcloud.generate_from_frequencies(word_counts)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Quiz Questions', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"WordCloud package not available. Install with: pip install wordcloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc8104",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Summary\n",
    "\n",
    "Let's summarize our findings about the boat license quiz questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb819d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for the dataset\n",
    "summary = {\n",
    "    \"Total Questions\": len(df),\n",
    "    \"Min Question Number\": df['question_number_numeric'].min(),\n",
    "    \"Max Question Number\": df['question_number_numeric'].max(),\n",
    "    \"Missing Question Numbers\": len(expected_range - all_numbers),\n",
    "    \"Duplicate Question Numbers\": len(duplicate_numbers),\n",
    "    \"Questions with 3 Options\": len(df[df['num_options'] == 3]),\n",
    "    \"Questions with Fewer Options\": len(df[df['num_options'] < 3]),\n",
    "    \"Most Common Correct Answer\": df['correct_answer'].value_counts().idxmax(),\n",
    "    \"Avg Question Length (chars)\": df['question_length'].mean(),\n",
    "    \"Avg Option Length (chars)\": (df['option_a_length'].mean() + df['option_b_length'].mean() + df['option_c_length'].mean()) / 3\n",
    "}\n",
    "\n",
    "# Display summary as a dataframe\n",
    "summary_df = pd.DataFrame(list(summary.items()), columns=['Metric', 'Value'])\n",
    "display(summary_df)\n",
    "\n",
    "# Print textual conclusion\n",
    "print(\"Key findings from the analysis of the boat license quiz questions:\")\n",
    "print(f\"1. The dataset contains {summary['Total Questions']} questions numbered from {summary['Min Question Number']} to {summary['Max Question Number']}.\")\n",
    "\n",
    "if summary['Missing Question Numbers'] > 0:\n",
    "    print(f\"2. There are {summary['Missing Question Numbers']} missing question numbers in the sequence.\")\n",
    "else:\n",
    "    print(\"2. The question numbering sequence is complete with no missing numbers.\")\n",
    "\n",
    "if summary['Duplicate Question Numbers'] > 0:\n",
    "    print(f\"3. There are {summary['Duplicate Question Numbers']} duplicate question numbers.\")\n",
    "else:\n",
    "    print(\"3. There are no duplicate question numbers.\")\n",
    "\n",
    "print(f\"4. {summary['Questions with 3 Options']} questions have all 3 options (a, b, c).\")\n",
    "\n",
    "if summary['Questions with Fewer Options'] > 0:\n",
    "    print(f\"5. {summary['Questions with Fewer Options']} questions have fewer than 3 options.\")\n",
    "else:\n",
    "    print(\"5. All questions have the expected 3 options.\")\n",
    "\n",
    "print(f\"6. The most common correct answer is option '{summary['Most Common Correct Answer']}'.\")\n",
    "print(f\"7. The average question length is {summary['Avg Question Length (chars)']:.1f} characters.\")\n",
    "print(f\"8. The average option length is {summary['Avg Option Length (chars)']:.1f} characters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
